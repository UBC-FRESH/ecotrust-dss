{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2952d534-038b-4367-9b3f-7603076adc1e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Overview\n",
    "\n",
    "This notebook imports raw ws3 input data, reformats and monkey-patches the data, and exports Woodstock formatted input data files (which we will use in other DSS notebooks for this case as the input data files). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8c11e-dbc1-48f1-996c-4109720d5efe",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49e412-0429-4b54-aa90-b3b1ce485693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23141f45-1925-43df-8bd4-0dfe8c3fc8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import ws3.forest, ws3.core\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial, wraps\n",
    "import distance\n",
    "import operator\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd44bc0-6b66-4dd1-9137-8ab51ec3b6b0",
   "metadata": {},
   "source": [
    "Define some key model parameters (will get used but defined here up top for convenience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46e712-2b73-41ee-bdb7-767683a16d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "period_length = 10\n",
    "max_age =  1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac1076-f791-4bbc-af1e-65037c58056a",
   "metadata": {},
   "source": [
    "Define paths required in the code to read and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078df09-2f9a-42ac-9b06-e390da3cdfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths\n",
    "shapefile_path = './data/shp_files/tsa17.shp/stands selection.shp'\n",
    "\n",
    "# Output paths\n",
    "stands_csv_path = './data/stands.csv'\n",
    "curve_points_table_csv_path = './data/curve_points_table.csv'\n",
    "\n",
    "yldmerged_csv_path = './data/yldmerged.csv'\n",
    "\n",
    "woodstock_model_files_lan_path = './data/woodstock_model_files_ecotrust/ecotrust.lan'\n",
    "woodstock_model_files_are_path = './data/woodstock_model_files_ecotrust/ecotrust.are'\n",
    "woodstock_model_files_yld_path = './data/woodstock_model_files_ecotrust/ecotrust.yld'\n",
    "woodstock_model_files_act_path = './data/woodstock_model_files_ecotrust/ecotrust.act'\n",
    "woodstock_model_files_trn_path = './data/woodstock_model_files_ecotrust/ecotrust.trn'\n",
    "contributing_area_path = './data/woodstock_model_files_ecotrust/aoi.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22316a-e1b1-4aff-8cb7-acdb520e985d",
   "metadata": {},
   "source": [
    "# Import and reformat inventory and yield input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167c8e8-ac87-4e9d-9a18-06d967d7949a",
   "metadata": {},
   "source": [
    "Read forest inventory data into memory (vector polygon GIS data layer with attribute table, in ESRI Shapefile format). This dataset represents timber supply area (TSA) in British Columbia. We monkey-patch the inventory data here to make it line up nicely with what we need downstream as input for the ws3 model (i.e., changes we make here to the in-memory dataset are not saved to the original dataset on disk). Most of what we are doing here is setting up the _theme_ columns in the attribute table, which should help newer ws3 users make the connection between input data and the landscape themes in ws3 model further down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7495ef3-e0db-458f-a94d-c31b02219e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "stands_org = gpd.read_file(shapefile_path)\n",
    "stands_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74024eb-0605-4278-9976-2f52bd78b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stands_org['forest_type'] = stands_org.apply(\n",
    "    lambda row: 1 if row['age2015'] > (60 + 10) else 2,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20712755-95da-481a-aef1-ffc28044d636",
   "metadata": {},
   "source": [
    "Import CANFI tree species lookup table (associates tree species names with integer numerical values, which we use as theme data values in the ws3 model), and insert species code values into the yield curve dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d8619-9d3e-476f-94fa-7e21a9e3a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['theme0', 'thlb', 'au', 'ldspp', 'age2015', 'shape_area', 'geometry','forest_type']\n",
    "stands = stands_org[columns_to_keep].copy()\n",
    "# stands['theme0'] = 'tsa01'\n",
    "columns = ['theme0'] + \\\n",
    "          [col for col in stands.columns if col not in ['theme0', 'forest_type']]  # Exclude these two\n",
    "columns.insert(4, 'forest_type')  # Insert 'primary_forest' at the 4th position\n",
    "stands = stands[columns]  # Apply new order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9813ced-42ac-4a56-88df-ca7bd54de05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582f4b6-100f-4c4e-b1e6-7a9382752aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "stands = stands.rename(columns={'thlb': 'theme1', 'au': 'theme2', 'ldspp': 'theme3', 'forest_type': 'theme5', 'age2015': 'age', 'shape_area': 'area' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a81c20-f13f-4bcb-b5ff-7c25bf400dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_missing_values(df):\n",
    "    new_rows = []\n",
    "    for value in df[\"theme2\"].unique():\n",
    "        # Filter rows where theme1 == 1 and theme2 matches the current value\n",
    "        subset = df[(df[\"theme2\"] == value) & (df[\"theme1\"] == 1)]\n",
    "        \n",
    "        if subset.empty:\n",
    "            continue  # Skip if no rows with theme1 == 1 for this theme2\n",
    "        \n",
    "        possible_values = {1, 2}\n",
    "        existing_values = set(subset[\"theme5\"])\n",
    "        missing_values = possible_values - existing_values\n",
    "        \n",
    "        for missing_value in missing_values:\n",
    "            # Use values from the first row in the subset as defaults\n",
    "            default_theme0 = subset[\"theme0\"].iloc[0]\n",
    "            default_theme3 = subset[\"theme3\"].iloc[0]\n",
    "            default_theme1 = subset[\"theme1\"].iloc[0]\n",
    "            default_theme4 = subset[\"theme4\"].iloc[0]\n",
    "            \n",
    "            new_row = {\n",
    "                \"theme0\": default_theme0,\n",
    "                \"theme1\": default_theme1,\n",
    "                \"theme2\": value,\n",
    "                \"theme3\": default_theme3,\n",
    "                \"theme4\": default_theme4,\n",
    "                \"theme5\": missing_value,\n",
    "                \"age\": 0,  # Default or placeholder value\n",
    "                \"area\": 1,  # Default or placeholder value\n",
    "            }\n",
    "            new_rows.append(new_row)\n",
    "    \n",
    "    # Append new rows to the DataFrame\n",
    "    df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddac590-1e3a-481a-b565-c5d7add8d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stands['area'] = stands.geometry.area * 0.0001\n",
    "# This code changes the type of \"theme2\" into integer\n",
    "stands['theme2'] = stands['theme2'].astype(int)\n",
    "# stands = ensure_missing_values(stands)\n",
    "stands.insert(4, 'theme4', stands['theme2'])\n",
    "stands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d42fcac-bff3-4972-81ca-38ebf5c07cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_contributing_areas = stands[stands['theme1'] == 1]['area'].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22c180-b7a8-47ca-ab3d-a8730dcd32ae",
   "metadata": {},
   "source": [
    "Read yield data from a CSV file and recast AU column data type to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee6900-4209-47ba-ada0-09b6720df5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading yld table and changing AU column type into integer\n",
    "yld = pd.read_csv('./data/yld.csv')\n",
    "yld['AU'] = yld['AU'].astype(int)\n",
    "yld"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e2533-1e41-437a-b539-811f6ecc2aa4",
   "metadata": {},
   "source": [
    "Create analysis unit (AU) dataframe from stands dataframe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa23ab8-4073-437a-a312-b04652110247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating AU table from stands table and renaming the column to AU. The AU table is then joined with yld table.\n",
    "AU = pd.DataFrame(stands['theme2']).drop_duplicates()\n",
    "AU.rename(columns = {'theme2':'AU'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88fff3-4ff7-4610-9af0-907eeb9a54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner joining AU and yld tables. The results of the code will be a yield table (yldmerged) that has AU column.\n",
    "yldmerged = pd.merge(AU, yld, on=['AU'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389eac4-e008-4121-96e1-35881d734437",
   "metadata": {},
   "outputs": [],
   "source": [
    "yldmerged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391b8d9d-0342-4e26-b196-4b8710d41c37",
   "metadata": {},
   "source": [
    "Import CANFI tree species lookup table (associates tree species names with integer numerical values, which we use as theme data values in the ws3 model), and insert species code values into the yield curve dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5930b67-0792-432b-b062-6bfc7ddd3251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting names and codes of canfi_species. This table will be used to add canfi_species column into yldmerged\n",
    "canf = pd.read_csv('data/canfi_species_revised.csv')\n",
    "canf = canf[['name','canfi_species']].set_index('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d69a4f-dc3a-4ee1-a940-24a4d62e6020",
   "metadata": {},
   "source": [
    "Burn CANFI species codes into stand and yield data tables."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0acb5c7a-3f62-4722-bc7f-1e54ebca0359",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Adding codes of leading species under canfi_species in the yldmerged\n",
    "for index, row in yldmerged.iterrows():\n",
    "    yldmerged.at[index,'canfi_species'] = canf.loc[row['LDSPP'],'canfi_species']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cda50-32da-405b-b5cf-79ebc156e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "yldmerged['canfi_species'] = yldmerged.apply(lambda row: canf.loc[row['LDSPP'], 'canfi_species'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a7c33-cbbe-4796-8338-606a46bb0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing leading species names with their codes\n",
    "for index, row in stands.iterrows():\n",
    "    stands.at[index,'theme6'] = canf.loc[row['theme3'],'canfi_species']\n",
    "stands['theme3'] = stands['theme6']\n",
    "# stands = stands.drop('theme6',axis=1)\n",
    "# stands['theme4'] = stands['theme2']\n",
    "stands['theme3'] = stands['theme3'] .astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90b679-14f5-46a9-885d-fb7684077eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "stands"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97ba64a6-d930-4fd2-a8ae-989850a15bf7",
   "metadata": {},
   "source": [
    "stands = ensure_missing_values(stands)\n",
    "# stands.insert(5, 'theme5', stands['theme4'])\n",
    "total_area = stands[stands['theme1'] == 1]['area'].sum()\n",
    "total_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3bbed-7510-48f6-a7fc-a4a74cb2ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_points_table = yldmerged\n",
    "# Adding 'curve_id' and 'canfi_species' columns to curve_points_table\n",
    "curve_points_table ['curve_id'] = curve_points_table ['AU']\n",
    "curve_points_table ['canfi_species'] = yldmerged ['canfi_species'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b953f-9f7e-4380-b341-7187ab129202",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_points_table.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01580ae6-28a6-4f0b-a866-830cb84c1b1f",
   "metadata": {},
   "source": [
    "\n",
    "new_rows = curve_points_table.copy()\n",
    "new_rows[\"curve_id\"] += 1\n",
    "\n",
    "# Combine original and new rows\n",
    "curve_points_table = pd.concat([curve_points_table, new_rows]).sort_index().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853e772-d0ab-476d-9189-8281c965748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_index_yld = ['AU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63ce79-7245-4c7b-b4f2-f8141d32c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_points_table = curve_points_table.set_index(columns_to_index_yld)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa16d12-9999-4fcf-a692-dff0eace518e",
   "metadata": {},
   "source": [
    "Save reformatted data to CSV files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa255222-d89d-498f-9e72-208229bd23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stands_.to_csv(stands_csv_path, index=False)\n",
    "# stands_mdf.to_csv(stands_mdf_csv_path, index=False)\n",
    "# yld_vdyp.to_csv(yld_vdyp_csv_path, index=False)\n",
    "yldmerged.to_csv(yldmerged_csv_path, header=True, index=False)\n",
    "stands.to_csv(stands_csv_path, header=True, index=False)\n",
    "curve_points_table.to_csv(curve_points_table_csv_path, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b412b-7879-4946-96e8-2283f10ceda4",
   "metadata": {},
   "source": [
    "# Export Woodstock-formatted input files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcec11d-55a0-4bc0-9abf-3c8470ecd359",
   "metadata": {},
   "source": [
    "We can use the new ws3 model instance we just built to export ws3 input files in Woodstock file format. We do this for three reasons. \n",
    "\n",
    "The first reason is that it will be simpler and more compact in the actual DSS notebook to instantiate the `ForestModel` object from these Woodstock-formatted files (and also this will provide an opportunity to demonstrate the existance and usage of the Woodstock model import functions that are built into ws3). \n",
    "\n",
    "The second reason is that the process of exporting data from a live `ws3.forest.ForestModel` instance to Woodstock-formatted input data files provides some insight into the internal structure and workings of ws3 models (which can be a challenging thing to get started with, particularly if you do not have a lot of experience building and running forest estate models). \n",
    "\n",
    "The third reason is that Woodstock file format is designed to be \"human readable\" (sort of... nobody ever said it would be super easy or super fun). Picking through the exported Woodstock-formatted files might help some people better understand the structure and details of the model we have built. If you have no experience reading Woodstock-formatted model input data files, then this is going to be trickier (unless you pause here and go take an introductory Woodstock training course of sort). Many forest professionals already have familiarity with Woodstock software and its special file format (through having been exposed to this at some point in their career). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3975c3-445b-4360-aa97-4ee6f132ebb5",
   "metadata": {},
   "source": [
    "Delete a folder containing previous woodstock files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed8ac3-83ec-434e-900a-efc25838bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder to remove\n",
    "folder_path = \"./data/woodstock_model_files_ecotrust\"\n",
    "\n",
    "# Check if the folder exists and remove it\n",
    "if os.path.exists(folder_path):\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(f\"Removed folder: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Folder does not exist: {folder_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091f1a07-2d2d-43d2-a79a-74faa5fe5594",
   "metadata": {},
   "source": [
    "Start by creating a new subdirectory to hold the new Woodstock-formatted data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ca420-87cb-4c13-8e13-84ebb62895e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir data/woodstock_model_files_ecotrust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75bc4b-300b-4aab-9953-345fabb63c46",
   "metadata": {},
   "source": [
    "## LANDSCAPE section\n",
    "\n",
    "The LANDSCAPE section defines stratification variables (themes) and stratification variable values (basecodes). "
   ]
  },
  {
   "cell_type": "raw",
   "id": "381f969a-5375-42c0-9c35-47a0311d720b",
   "metadata": {},
   "source": [
    "# # Exporting the value to a CSV file\n",
    "# with open(contributing_area_path, 'w') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     # writer.writerow([\"Sum of Area\"])  # Optional header\n",
    "#     writer.writerow([aoi_contributing_areas])       # Writing the value\n",
    "# Writing the value to a text file\n",
    "with open(contributing_area_path, 'w') as file:\n",
    "    file.write(str(aoi_contributing_areas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2f67a-680e-4d07-ba75-c3be6b8b55bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_cols=['theme0', # TSA \n",
    "            'theme1', # THLB\n",
    "            'theme2', # AUs\n",
    "            'theme3', # leading species code\n",
    "            'theme4',  # yield curve ID\n",
    "            'theme5',  # forest type\n",
    "           ]\n",
    "basecodes = [list(map(lambda x: str(x), stands[tc].unique())) for tc in theme_cols]\n",
    "basecodes[2] = list(set(basecodes[2] + list(stands['theme2'].astype(str))))\n",
    "basecodes[3] = list(set(basecodes[3] + list(stands['theme3'].astype(str))))\n",
    "# basecodes[4] = list(set(basecodes[4] + list((stands['theme2'] * 1000 + 1).astype(str)) + list((stands['theme2'] * 1000 + 2).astype(str))))\n",
    "basecodes[4] = list(set(basecodes[4] + list(stands['theme4'].astype(str))))\n",
    "basecodes[5] = list(set(basecodes[5] + list(stands['theme5'].astype(str))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609cabc-4c63-4f1d-9637-aa5cb571a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basecodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5d6d6-6628-4a9a-a02f-bff9a396d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(woodstock_model_files_lan_path, 'w') as file:\n",
    "    print('*THEME Timber Supply Area (TSA)', file=file)\n",
    "    # print('tsa01',file=file)\n",
    "    for basecode in basecodes[0]: print(basecode, file=file)\n",
    "    print('*THEME Timber Harvesting Land Base (THLB)', file=file)\n",
    "    for basecode in basecodes[1]: print(basecode, file=file)\n",
    "    print('*THEME Analysis Unit (AU)', file=file)\n",
    "    for basecode in basecodes[2]: print(basecode, file=file)\n",
    "    print('*THEME Leading tree species (CANFI species code)', file=file)\n",
    "    for basecode in basecodes[3]: print(basecode, file=file)\n",
    "    print('*THEME Yield curve ID', file=file)\n",
    "    for basecode in basecodes[4]: print(basecode, file=file)\n",
    "    print('*THEME Forest Type', file=file)\n",
    "    for basecode in basecodes[5]: print(basecode, file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfd8d8-9d46-43e3-a819-05205e5bf4eb",
   "metadata": {},
   "source": [
    "## AREAS section\n",
    "\n",
    "The AREAS section defines the initial forest inventory, in terms of how many hectares of which age class are present in which development type (where a development type is defined as a unique sequence of landscape theme variable values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf87ae-1249-47f1-aa8e-89ea78e6b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gstands = stands.groupby(theme_cols+['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a705cf-abd6-4fa5-acc6-7e739f384e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(woodstock_model_files_are_path, 'w') as file:\n",
    "    age_cutoff = 600\n",
    "    for name, group in gstands:\n",
    "        dtk, age, area = tuple(map(lambda x: str(x), name[:-1])), int(name[-1]), group['area'].sum()\n",
    "        print('*A', ' '.join(v for v in dtk), age, round(area, 10), file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f3ef0-2168-4757-a8b5-d8075f85e068",
   "metadata": {},
   "source": [
    "## YIELDS section\n",
    "\n",
    "The YIELDS section defines yield curves (in this example we only track merchantable log volume, but we can use yield curves to track all sorts of other stuff). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b300af-fba1-4ce2-bd71-beee2eb2d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_points_table['forest_type'] = 1\n",
    "new_rows = curve_points_table.copy()\n",
    "new_rows[\"forest_type\"] += 1\n",
    "\n",
    "# Combine original and new rows\n",
    "curve_points_table = pd.concat([curve_points_table, new_rows]).sort_index().reset_index(drop=True)\n",
    "\n",
    "curve_points_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2396d3-bfba-44c7-b272-e93246cd0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(woodstock_model_files_yld_path, 'w') as file:\n",
    "        tot=[]\n",
    "        swd=[]\n",
    "        hwd=[]\n",
    "        for AU, au_row in curve_points_table.iterrows():\n",
    "            yname = 's%04d' % int(au_row.canfi_species)    \n",
    "            curve_id = au_row.curve_id\n",
    "            forest_type = au_row.forest_type\n",
    "            mask = ('?', '?', str(curve_id), '?', str(curve_id), str(forest_type))\n",
    "            points = [(x*10, au_row['X%i' % (x*10)]) for x in range(36)]\n",
    "            c = ws3.core.Curve(yname, points=points, type='a', is_volume=True, xmax=max_age, period_length=period_length)\n",
    "            print('*Y', ' '.join(v for v in mask), file=file)\n",
    "            print(yname, '1', ' '.join(str(int(c[x])) for x in range(0, 350, 10)), file=file)\n",
    "            if yname not in tot:\n",
    "                tot.append(yname)\n",
    "            if int(au_row.canfi_species) > 1200:\n",
    "                if yname not in hwd: hwd.append(yname)\n",
    "            else:\n",
    "                if yname not in swd: swd.append(yname)\n",
    "        print('*YC ? ? ? ? ? ?', file=file)\n",
    "        print('totvol _SUM(%s)' % ', '.join(map(str, tot)), file=file)\n",
    "        print('swdvol _SUM(%s)' % ', '.join(map(str, swd)), file=file)\n",
    "        print('hwdvol _SUM(%s)' % ', '.join(map(str, hwd)), file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b29c9-4151-4480-9b01-3bd9a98f7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(8, 12), sharex=True)\n",
    "\n",
    "cvol = c\n",
    "ccai = c.cai()\n",
    "cmai = c.mai()\n",
    "cmaiytp = c.mai().ytp()\n",
    "x_cmai = cmaiytp.lookup(0) # optimal rotation age (i.e., culmination of MAI curve)\n",
    "labels = 'total volume', 'MAI (and CAI)', 'MAI YTP'\n",
    "\n",
    "ax[0].plot(*zip(*c.points()))\n",
    "ax[0].plot([0, x_cmai], [0., cvol[x_cmai]], linestyle='--', color='green')\n",
    "\n",
    "ax[1].plot(*zip(*c.mai().points()))\n",
    "ax[1].plot(*zip(*c.cai().points()), linestyle=':')\n",
    "\n",
    "ax[2].plot(*zip(*c.mai().ytp().points()))\n",
    "ax[2].axhline(0, color='black')\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    ax[i].set_ylabel(labels[i])\n",
    "    ax[i].set_ylim(0, None)\n",
    "    ax[i].axvline(x_cmai, color='red')\n",
    "plt.xlim(0, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a91dffe-81ae-4986-b79a-a0333d18fbd3",
   "metadata": {},
   "source": [
    "## ACTIONS section\n",
    "\n",
    "The ACTIONS section defines actions that can be applied in the model (e.g., harvesting, planting, thinning, fertilization, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9332a-fc69-4673-8d5c-9c1b1481f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(woodstock_model_files_act_path, 'w') as file:\n",
    "    print('ACTIONS', file=file)\n",
    "    print('*ACTION harvest Y', file=file)\n",
    "    print('*OPERABLE harvest', file=file)\n",
    "    print('? 1 ? ? ? ? _AGE >= 90 AND _AGE <= 600', file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2265df-4b0e-4182-be58-e9a96663b912",
   "metadata": {},
   "source": [
    "## TRANSITIONS section\n",
    "\n",
    "The TRANSITIONS section defines transitions (i.e., transition to a new development type and age class induced by applying a specific action to a specific combination of development type and age class). If there were no transitions in a forest estate model, it would simply be aging (i.e., growing) the forest forward from time step 1 through to time step N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c3f19-32e8-46c9-853f-4938505d008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(woodstock_model_files_trn_path, 'w') as file:\n",
    "    acode = 'harvest'\n",
    "    print('*CASE', acode, file=file)\n",
    "    record_au = set()\n",
    "    for au_id, au_row in stands.iterrows():\n",
    "        if au_row.theme2 in record_au: continue\n",
    "        if not au_row.theme1: continue\n",
    "        au = au_row.theme2\n",
    "        target_curve_id = au\n",
    "        # primary_determinant = au_row.theme5\n",
    "        # smask = ' '.join(('?', '?', '?', '?', '?', str(target_curve_id)))\n",
    "        # tmask = ' '.join(('?', '?' , '?', '?', str(target_curve_id), '?'))\n",
    "        # smask_primary = ' '.join(('?', '?' , str(target_curve_id), '?', '?', '1'))\n",
    "        # tmask_primary = ' '.join(('?', '?' , '?', '?', str(target_curve_id), '0'))\n",
    "        # smask_secondary = ' '.join(('?', '?' , str(target_curve_id), '?', '?', '0'))\n",
    "        # tmask_secondary = ' '.join(('?', '?' , '?', '?', str(target_curve_id), '0'))\n",
    "        smask = ' '.join(('?', '1' , str(au), '?', '?', '?'))\n",
    "        tmask = ' '.join(('?', '?' , '?', '?', str(target_curve_id), '2'))\n",
    "\n",
    "        print('*SOURCE', smask, file=file)\n",
    "        print('*TARGET', tmask, '100', file=file)\n",
    "\n",
    "        record_au.add(au_row.theme2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe7752-6c10-46c6-99c6-76cd933cae3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c95d0d-e63c-4a9d-b493-ddf4350a3495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (venv:foo)",
   "language": "python",
   "name": "foo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
